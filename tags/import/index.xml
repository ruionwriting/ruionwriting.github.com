<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Import on Rui Marques</title>
    <link>http://localhost:1313/tags/import/</link>
    <description>Recent content in Import on Rui Marques</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>Rui Marques</copyright>
    <lastBuildDate>Sat, 12 Apr 2014 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/import/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>SQL Server: (re)import CSV data the easy way</title>
      <link>http://localhost:1313/blog/2014/04/12/sql-server-re-import-csv-data-the-easy-way/</link>
      <pubDate>Sat, 12 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/blog/2014/04/12/sql-server-re-import-csv-data-the-easy-way/</guid>
      <description>

&lt;p&gt;Importing data into SQL Server is not hard using the import data feature but I really don&amp;rsquo;t appreciate the fact that there is no way to save that import profile/rules for later reuse. Solution: use BULK INSERT from a regular reusable sql script.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://technet.microsoft.com/en-us/library/ms188365.aspx&#34;&gt;BULK INSERT (Transact-SQL)&lt;/a&gt; is a really nice feature that allows to easily create a reusable data import script capable of import one or many CSV files. I&amp;rsquo;m going to build a simple script using this nice feature.&lt;/p&gt;

&lt;p&gt;For this example I have a simple CSV file containing a set of data from a fictional marketing contacts database.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;json&#34;&gt;Id;Name;EmailAddress;MobileNumber
1;John;john@gmail.com;123456789
2;Mary;mary@gmail.com;123456789
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to use BULK INSERT I need the target table structure to have the same structure as the source data. Not always this would be the case so I&amp;rsquo;m going to create a temporary table to hold my source data that will be retrieved from the BULK INSERT.&lt;/p&gt;

&lt;h2 id=&#34;creating-the-temporary-table:7e7499f147e9fa1679b6c7ba5326a17f&#34;&gt;Creating the temporary table&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;sql&#34;&gt;-- Temporary table to hold CSV data
CREATE TABLE #tempSource_Table_Name (
    Id int,
    [Name] nvarchar(500),
    EmailAddress nvarchar(500) null,
    MobileNumber nvarchar(500) null
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This temporary table columns definitions should reflect the source structure and columns types.&lt;/p&gt;

&lt;p&gt;Now that I have a temporary table that can receive the source data from the CSV.&lt;/p&gt;

&lt;h2 id=&#34;building-the-bulk-insert-script:7e7499f147e9fa1679b6c7ba5326a17f&#34;&gt;Building the BULK INSERT script&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;sql&#34;&gt;BULK INSERT #tempSource_Table_Name
FROM &#39;C:\csv_file_full_path\source_table_data.csv&#39;
WITH
(
    FIRSTROW = 2,
    FIELDTERMINATOR = &#39;;&#39;,
    ROWTERMINATOR = &#39;\n&#39;,
    CODEPAGE = &#39;ACP&#39;
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m just applying a short set of the &lt;a href=&#34;http://technet.microsoft.com/en-us/library/ms188365.aspx&#34;&gt;available arguments&lt;/a&gt;. Based on your data source apply the necessary arguments.&lt;/p&gt;

&lt;p&gt;This is a very powerful tool. Just for the example, is possible to have a source data file from a UNC share, take control over encoding, etc.&lt;/p&gt;

&lt;p&gt;Now that I have a temporary table containing the imported data I can insert it to my target table applying some extra import rules and tweaks.&lt;/p&gt;

&lt;h2 id=&#34;building-the-insert-script-for-the-target-table:7e7499f147e9fa1679b6c7ba5326a17f&#34;&gt;Building the insert script for the target table&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;sql&#34;&gt;-- insert data to target table
INSERT INTO [dbo].[Target_Table_Name]
   ([Name]
   ,[MobileNumber]
   ,[EmailAddress]
   ,[Password]
   ,[LastKnownIPAddress]
   ,[CreatedOn]
   ,[ChangedOn]
   ,[VerifiedOn]
   ,[Blocked]
   ,[BlockEmailMarketing])
SELECT
    [Name]
    ,[MobileNumber]
    ,(
        CASE
            WHEN [EmailAddress] IS NULL
                THEN CONCAT(CONVERT(varchar, [Id]), &#39;@example.com&#39;)
            ELSE [EmailAddress]
        END
    )
    ,NULL
    ,NULL
    ,(SELECT GETDATE())
    ,NULL
    ,NULL
    ,0
    ,0          
FROM #tempSource_Table_Name
-- apply any addional filtering/sorting as needed
-- WHERE [Id] IS NOT NULL
-- ORDER BY EmailAddress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This example shows that is quite easy to apply some data transformations to the source data before inserting it on my target table. All the power of Transact-SQL is available to make a serious import script using this strategy.&lt;/p&gt;

&lt;h2 id=&#34;improvement-ideas:7e7499f147e9fa1679b6c7ba5326a17f&#34;&gt;Improvement ideas&lt;/h2&gt;

&lt;p&gt;Also I want to add to my import script some extra features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;perform all my operations wrapped within a transaction;&lt;/li&gt;
&lt;li&gt;sanitize data before import (useful I want to test the import multiple times);&lt;/li&gt;
&lt;li&gt;demonstrate that is easy to import multiple files in one run.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;full-script:7e7499f147e9fa1679b6c7ba5326a17f&#34;&gt;Full script&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;sql&#34;&gt;/*
    set target database
*/

USE [Target_Database_Name]
GO

/*
    wrap everything in a transaction
*/

BEGIN TRAN
GO

/*
    (optional) sanitize target table(s)
*/

-- remove all rows
DELETE FROM [Target_Table_Name];
GO

-- if your the target table contains a identity key, reset its value
DBCC CHECKIDENT ([Target_Table_Name], reseed, 0)
GO

-- extra sanitization operations like disabling triggers, FK&#39;s, etc

/*
    creat a temp table, for each CSV that you wish to import, to hold CSV data

    example CSV:

    Id;Name;EmailAddress;MobileNumber
    1;John;john@gmail.com;123456789
    2;Mary;mary@gmail.com;123456789

    table structure and column types must match with the CSV
*/

CREATE TABLE #tempSource_Table_Name (
    Id int,
    [Name] nvarchar(500),
    EmailAddress nvarchar(500) null,
    MobileNumber nvarchar(500) null
);
GO

/*
    import CSV data to the temp table
*/

BULK INSERT #tempSource_Table_Name
FROM &#39;C:\csv_file_full_path\source_table_data.csv&#39;
WITH
(
    FIRSTROW = 2,
    FIELDTERMINATOR = &#39;;&#39;,
    ROWTERMINATOR = &#39;\n&#39;,
    CODEPAGE = &#39;ACP&#39;
);
GO

/*
    insert data to the target table using temp table as the source
    apply as many rules as needed to transform imput data
*/

INSERT INTO [dbo].[Target_Table_Name]
   ([Name]
   ,[MobileNumber]
   ,[EmailAddress]
   ,[Password]
   ,[LastKnownIPAddress]
   ,[CreatedOn]
   ,[ChangedOn]
   ,[VerifiedOn]
   ,[Blocked]
   ,[BlockEmailMarketing])
SELECT
    [Name]
    ,[MobileNumber]
    ,(
        CASE
            WHEN [EmailAddress] IS NULL
                THEN CONCAT(CONVERT(varchar, [Id]), &#39;@example.com&#39;)
            ELSE [EmailAddress]
        END
    )
    ,NULL
    ,NULL
    ,(SELECT GETDATE())
    ,NULL
    ,NULL
    ,0
    ,0          
FROM #tempSource_Table_Name
-- apply any addional filtering/sorting as needed
-- WHERE [Id] IS NOT NULL
-- ORDER BY EmailAddress

GO

/*
    drop temp table(s)
*/

DROP TABLE #tempSource_Table_Name;
GO

/*
    extra operations
*/

-- enable triggers, FK&#39;s, etc

/*
    all good, time to commit transaction
*/

COMMIT TRAN
GO
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>